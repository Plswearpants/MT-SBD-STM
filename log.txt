11-28-2024
some feedbacks from Jisun and Sarah on the benchmark datasets:
1. symmetry of the kernel may not be the same in real cases, the feature of QPI might be the same, but the feature of defects might not.
2. theta_cap/pixel and image_size may not be good parameters, as in the physical case, optimal density of pixel per nm is defined by the 
    target resolution in real space(and target range of the q-space), therefore, the real considerations are:
    a) size of unit cell in real space -> determines pixel per nm 
    b) helium/ nitrogen holding time -> determines total pixel number 
3. SNR should be defined with respect to the noise level of the detector, which need further investigation. 


12-03-2024
- Markus's feedback on the consistency of the algorithm: 
We should run the algorithm multiple times on the same dataset with the same initial conditions and see if the results are the same. Maybe say 5 times.

- Dong's feedback: 
Want residual metrics, defined as Residual quality: var(noise)/var(Y-sum-(Y_each_kernel)), already exists in computeResidualQuality.m
Want to create a demixing metric, verbally defined as how successful the algorithm is in separating the individual kernels.
    This can be done by: sum_all(cross-correlation(2 activations, exclude self-correlation)), this give a scalar, but could also save the matrix, in case want to see which ones are most correlated. 

12-04-2024 
- Sarah's feedback: 
Test case: different defect structure and simmilar QPI features -> different kernels: 2 lobes with 2 orientations.
test case in STM 
todo: single test on kernel number 
cross-relation between sparsity and lembda1. 
lembda1 on the other direction. 2 lembda1 values. 

12.09-2024
- what I did today:
1. Created an interactive visualization system with:
    a) Parameter-specific views with dataset highlighting
    b) Overview plots showing all parameter combinations
    c) Robust error handling for dataset descriptions
    d) Proper legend management
2. Improved the demixing metric by:
    a) Making it more intuitive (higher is better)
    b) Normalizing appropriately
    c) Adding proper documentation
3. Created comprehensive documentation for all metrics in LaTeX format
4. Made the visualization system more robust with:
    a) Proper UI scaling
    b) Error handling
    c) Consistent styling across different views

12.31-2024:
1. Create a synthetic rotational dataset. 

1.13-2025
1. combine the 2 synthetic datasets. 
result: not particularly useful. 

Optimal parameter selection: 
lambda1: 0.1 or 0.3  
mini-loop: 1 or 3

What was Doug's concern? 
Dataset generation should have a kernel with inifite size.


technicially, a good way to compare is to fix other parameters, in our case, the way to create a synthetic dataset is:
1. vary theta_cap, create different activations accordingly.
2. given a activation, create a dataset with different area ratio. 
3. given a activation and area ratio, create a dataset with different SNR. 

Steps: 
%% 1. Initial Setup
% - Load LDoS data
% - Get kernel selections
% - Define parameter ranges
% - Set fixed parameters

%% 2. Generate Base Activations
% - For each theta_cap value
% - Store activation maps and parameters

%% 3. Create Kernel Size Variations
% - For each base activation
% - For each area ratio
% - Store results and parameters

%% 4. Add Noise Variations
% - For each (activation, kernel size) combination
% - For each SNR value
% - Store final results

%% 5. Save and Visualize Results
% - Organize results in a structured way
% - Save with clear parameter descriptions
% - Create visualization tools for browsing datasets


1.15-2025
Today, I will address Doug's concern on the dataset generation. 
